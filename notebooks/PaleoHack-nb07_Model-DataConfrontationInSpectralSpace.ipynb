{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/LinkedEarth/Logos/raw/master/PYLEOCLIM_logo_HORZ-01.png' width=\"800\">\n",
    "\n",
    "# 7. Model-Data Confrontation #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we demonstrate how to use `Pyleoclim` for spectral analysis of proxy records and model simulations, along with their visualization.\n",
    "\n",
    "In the 1st part, to introduce the spectral analysis funtionalities, we reproduce the results of [Zhu et al. (2019)](https://www.pnas.org/content/early/2019/04/09/1809959116).\n",
    "\n",
    "In the 2nd part, a practictum, encourages you to play with the functionalities, with the help of the [documentation](https://pyleoclim-util.readthedocs.io/en/latest/core/ui.html#), and compare the results from different spectral analysis methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load essential packages\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pyleoclim as pyleo  # make an alias name for \"pyleoclim\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: a presentation of the `Pyleoclim` spectral analysis functionalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GMST data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load PMIP3 simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PMIP3([Braconnot et al. 2012](https://www.nature.com/articles/nclimate1456))  simulations  of the past millennium ([past1000](https://wiki.lsce.ipsl.fr/pmip3/doku.php/pmip3:design:lm:final)) of global mean surface temperature (GMST) are stored in a text file and can be imported with `Pandas` conveniently.\n",
    "The file includes several ensemble members for CESM and GISS simulations, for which we substitue their ensemble mean series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the raw data\n",
    "df = pd.read_table('../data/PMIP3_GMST.txt')\n",
    "\n",
    "# display the raw data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new pandas.DataFrame to store the processed data\n",
    "df_new = df.copy()\n",
    "\n",
    "# remove the data columns for CESM and GISS ensemble members\n",
    "for i in range(10):\n",
    "    df_new = df_new.drop([f'CESM_member_{i+1}'], axis=1)\n",
    "    \n",
    "df_new = df_new.drop(['GISS-E2-R_r1i1p127.1'], axis=1)\n",
    "df_new = df_new.drop(['GISS-E2-R_r1i1p127'], axis=1)\n",
    "df_new = df_new.drop(['GISS-E2-R_r1i1p121'], axis=1)\n",
    "\n",
    "# calculate the ensemble mean for CESM and GISS, and add the results into the table\n",
    "df_new['CESM'] = df[[\n",
    "    'CESM_member_1',\n",
    "    'CESM_member_2',\n",
    "    'CESM_member_3',\n",
    "    'CESM_member_4',\n",
    "    'CESM_member_5',\n",
    "    'CESM_member_6',\n",
    "    'CESM_member_7',\n",
    "    'CESM_member_8',\n",
    "    'CESM_member_9',\n",
    "    'CESM_member_10',\n",
    "]].mean(axis=1)\n",
    "\n",
    "df_new['GISS'] = df[[\n",
    "    'GISS-E2-R_r1i1p127.1',   \n",
    "    'GISS-E2-R_r1i1p127',\n",
    "    'GISS-E2-R_r1i1p121',\n",
    "]].mean(axis=1)\n",
    "\n",
    "# display the processed data\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a `pyleoclim.Series` object for each simulated GMST time series.\n",
    "A `pyleoclim.Series` represents a time series object that comes with a collection of methods, such as performing spectral analysis, wavelet analysis, interpolation, plotting, and so on.\n",
    "For details, see [the documentation](https://pyleoclim-util.readthedocs.io/en/stable/core/ui.html#series-pyleoclim-series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store each pyleoclim.Series() object into a dictionary\n",
    "ts_dict = {}\n",
    "for name in df_new.columns[1:]:\n",
    "    ts_dict[name] = pyleo.Series(\n",
    "        time=df_new['Year'].values,  # the time axis\n",
    "        value=df_new[name].values,   # the value axis\n",
    "        label=name,                  # optional metadata: the nickname of the series\n",
    "        time_name='Time',            # optional metadata: the name of the time axis\n",
    "        time_unit='yrs',             # optional metadata: the unit of the time axis\n",
    "        value_name='GMST anom.',     # optional metadata: the name of the value axis\n",
    "        value_unit='K',              # optional metadata: the unit of the value axis\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a `pyleoclim.Series` is defined, we can easily visualize it by calling the `pyleoclim.Series.plot()` method.\n",
    "For instance, we plot the CCSM4 GMST below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = ts_dict['CCSM4'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the return of the `plot()` method is a list of a `matplotlib.pyplot.figure` and a `matplotlib.pyplot.axis`.\n",
    "That means all possible `matplotlib` manipulations can follow.\n",
    "For instance, let's change the limit of the y-axis and the label below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = ts_dict['CCSM4'].plot(mute=True, label='CCSM4 series')  # the argument \"mute=True\" means to hold the display\n",
    "ax.set_ylim([-4, 2])\n",
    "pyleo.showfig(fig)  # display the final presentation of the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when we want to modify on the original `fig` and `ax` returned from `pyleoclim.Series.plot()`, we need to use the `mute=True` argument to first hold the display of the figure, and then use `pyleoclim.showfig(fig)` to display the final presentation of the figure.\n",
    "\n",
    "With the same mechanism, we may plot two time series in the same figure as following, in which we use the argument `ax=ax` to specify that the we'd like to plot the series of GISS into the same `matplotlib.pyplot.axis`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = ts_dict['CCSM4'].plot(mute=True)\n",
    "ts_dict['GISS'].plot(ax=ax)  # the argument \"ax=ax\" indicates we'd like to plot into the \"ax\" we got from the previous line of code \n",
    "ax.set_ylim([-4, 2])\n",
    "pyleo.showfig(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a way to plot a collection of time series at once? Absolutely.\n",
    "We can define a `pyleoclim.MultipleSeries` object, which takes a list of `pyleoclim.Series` objects as input.\n",
    "\n",
    "Since we have defind a dictionary of a collection of `pyleoclim.Series` objects, we may first convert this dictionary into a list, and then use that list to define a `pyleoclim.MultipleSeries` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_list = [v for k, v in ts_dict.items()]  # a pythonic way to convert the pyleo.Series items in the dictionary to a list\n",
    "ms_pmip = pyleo.MultipleSeries(ts_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the `pyleoclim.MultipleSeries` called \"ms_pmip\" is defined, we can visualize all the time series at once by calling the `pyleoclim.MultipleSeries.plot()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = ms_pmip.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that the legend is not in its best place, and we may want to move it to the right side.\n",
    "We can achieve that by passing a dictionary of arguments for `matplotlib.pyplot.axis.legend()` (see the [matplotlib documentation](https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.legend.html) for details) as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = ms_pmip.plot(\n",
    "    lgd_kwargs={\n",
    "        'bbox_to_anchor': (1.25, 1),  # move the legend to the right side\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the loading of PMIP3 simulations is complete, let's move on to proxies, the [last millennium reanalysis](https://cpo.noaa.gov/News/News-Article/ArtMID/6226/ArticleID/1807/Last-Millennium-Reanalysis-now-at-NOAAs-National-Centers-for-Environmental-Information-marking-major-milestone) (LMR, [Hakim et al. 2016](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2016JD024751), [Tardif et al. 2019](https://cp.copernicus.org/articles/15/1251/2019/)), and deglacial simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load proxies, LMR, and deglacial simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've preprocessed the data for proxies, LMR, and deglacial simulations, and stored them in a [Python pickle](https://docs.python.org/3/library/pickle.html) file, which includes two dictionaries called `ts` and `vs`.\n",
    "`ts` includes the time axis for each dataset,\n",
    "and `vs` includes the GMST for each dataset.\n",
    "\n",
    "We load the pickle file below and print out the dictionary keys to see how many datasets we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/PNAS19_data.pkl', 'rb') as f:\n",
    "    ts, vs = pickle.load(f)\n",
    "    \n",
    "print(vs.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we extract the data and organize them in a `Series` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in vs.keys():\n",
    "    # we may specify specific metadata for each dataset with the if-clauses\n",
    "    if name == 'LMR':\n",
    "        value_name = 'GSMT anom.'\n",
    "        value_unit = 'K'\n",
    "    elif name in ['trace21ka_full', 'DGns', 'SIM2bl']:\n",
    "        value_name = 'GSMT'\n",
    "        value_unit = 'K'\n",
    "    else:\n",
    "        value_name = 'Proxy Value'\n",
    "        value_unit = None\n",
    "        \n",
    "    if name == 'trace21ka_full':\n",
    "        label = 'TraCE-21ka'\n",
    "    elif name in ['trace21ka_mwf', 'trace21ka_orb', 'trace21ka_ghg', 'trace21ka_ice']:\n",
    "        continue\n",
    "    else:\n",
    "        label = name\n",
    "        \n",
    "    ts_dict[name] = pyleo.Series(\n",
    "        time=ts[name],\n",
    "        value=vs[name],\n",
    "        label=label,\n",
    "        time_name='Time',\n",
    "        time_unit='yrs',\n",
    "        value_name=value_name,\n",
    "        value_unit=value_unit,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a `MultipleSeries` object for each group of datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_obs = pyleo.MultipleSeries(\n",
    "    [ts_dict[name] for name in ['EDC', 'HadCRUT4', 'GAST', 'ProbStack']]\n",
    ")\n",
    "ms_deglacial = pyleo.MultipleSeries(\n",
    "    [ts_dict[name] for name in ['trace21ka_full', 'DGns', 'SIM2bl']]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we visualize what we have.\n",
    "LMR first.\n",
    "\n",
    "Note that here we use the median of the LMR ensembles for our analysis for simplicity and calculation speed, while all the ensemble members are being analyzed in the original paper, so the estimated scaling slope value that we show later would be a bit different from that in the original paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = ts_dict['LMR'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the proxies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = ms_obs.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the time axis is in unit of years by default, which is odd for paleo-records prior to CE.\n",
    "We can easily convert the time unit to \"kyrs BP\" by calling the `pyleoclim.MultipleSeries.convert_time_unit` method as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_obs = ms_obs.convert_time_unit('myrs BP')\n",
    "fig, ax = ms_obs.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now the time unit is \"myrs BP\", and the numerical time values are ascending.\n",
    "What if we'd like to present the data in a way that the right hand side represents more recent time?\n",
    "Well, we can manipulate the returned `matplotlib.pyplot.axis` object as mentioned earlier, or just use the `invert_xais=True` argument of the `pyleoclim.MultipleSeries.plot()` method as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = ms_obs.plot(invert_xaxis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we convert the time unit of deglacial simulations to \"kyrs BP\" and then visualize them with the x-axis inverted and the lelgend location moved to the right side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_deglacial = ms_deglacial.convert_time_unit('kyrs BP')\n",
    "fig, ax = ms_deglacial.plot(\n",
    "    lgd_kwargs={\n",
    "        'loc': 'upper right',         # put the legend anchor to the upper right corner\n",
    "        'bbox_to_anchor': (1.25, 1),  # move the legend to the right side\n",
    "    },\n",
    "    invert_xaxis=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all data needed has been loaded, let's perform spectral analysis using the Weighted Wavelet Z-transform method (WWZ)([Foster 1996](https://ui.adsabs.harvard.edu/abs/1996AJ....112.1709F), [Kirchner & Neal 2013](https://www.pnas.org/content/110/30/12213)), which can handle unevenly-spaced data without interpolation. (see notebook 6 for more details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral analysis using WWZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may perform spectral analysis on time series by calling the `pyleoclim.Series.spectral()` method.\n",
    "It has the argument `method` to specify which method to use. It is set to `wwz` by default to use the WWZ method. \n",
    "It also has an argument `freq_method` to specify the approach to generate the frequency vector for the analysis.\n",
    "It is set to `log` by default to use generate the frequency vector in a log space.\n",
    "Here, we set to `nfft` so that we can reproduce the result in the original paper [Zhu et al. (2019)](https://www.pnas.org/content/early/2019/04/09/1809959116).\n",
    "Other arguments specific to each spectral analysis method can be passed in through the argument `settings`.\n",
    "Since WWZ is originally a wavelet analysis method, we may specify `tau` to specify the evenly-spaced time points (the temporal resolution) for wavelet analysis.\n",
    "However, since our purpose here is spectral analysis, the temporal resolution is not required to be high, and we may use small values to accelerate the calculation.\n",
    "Please see the documentation on [pyleoclim.Series.spectral](https://pyleoclim-util.readthedocs.io/en/stable/core/Series/spectral.html#pyleoclim.core.ui.Series.spectral) and the [wwz_psd](https://pyleoclim-util.readthedocs.io/en/stable/utils/spectral/wwz_psd.html?highlight=wwz_psd) function that `pyeloclim.Series.spectral` called for details.\n",
    "\n",
    "The method will return a [pyleoclim.PSD](https://pyleoclim-util.readthedocs.io/en/stable/core/ui.html#psd-pyleoclim-psd) object, which includes the estimated power spectral density (PSD) along with the information of the frequency axis, and the object iteself is intended for lalter operations such as visualization, scaling slope estimation, and significance test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that to reproduce exactly the result in the paper, we need to use settings in the cell below (that's commented out), which could be slow (> 5 mins).\n",
    "For the sake of time, we may load a file with pre-calculated results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # we will store the result in a dictionary with the dataset names as keys\n",
    "# psd_wwz = {}\n",
    "# for name, ts in ts_dict.items():\n",
    "#     print(f'Processing {name} ...')\n",
    "#     print(f'Data length: {np.size(ts.time)}')\n",
    "#     if name in ['DGns', 'SIM2bl']:\n",
    "#         ntau = 51  # to accelerate the calculation; the smaller, the faster\n",
    "#     else:\n",
    "#         ntau = 501\n",
    "#     tau = np.linspace(np.min(ts.time), np.max(ts.time), ntau)\n",
    "#     psd_wwz[name] = ts.spectral(method='wwz', freq_method='nfft', settings={'tau': tau})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick loading of the pyleoclim.PSD objects\n",
    "with open('../data/PNAS19_psd.pkl', 'rb') as f:\n",
    "    psd_wwz = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may, however, perform the WWZ method with the default settings that makes the calculation faster, and compare with the pre-calculated results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "psd_wwz_new = {}\n",
    "for name, ts in ts_dict.items():\n",
    "    print(f'Processing {name} ...')\n",
    "    print(f'Data length: {np.size(ts.time)}')\n",
    "    psd_wwz_new[name] = ts.spectral(method='wwz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in psd_wwz_new.keys():\n",
    "    fig, ax = psd_wwz_new[k].plot(figsize=[5, 2], mute=True, label='new')\n",
    "    psd_wwz[k].plot(ax=ax, label='paper', color='red', alpha=1)\n",
    "    ax.set_title(k)\n",
    "    pyleo.showfig(fig, close=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the difference is overall rather small.\n",
    "Indeed, the difference is mainly caused by the frequency vector: the results of the paper used a linear spaced frequency vector while the current default settings used a log space vector.\n",
    "For the following presentation, we will stick with the pre-calculated results of the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization the PSD objects returned from the spectral analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize the results.\n",
    "In below cells, we first define a colormap, then specify the colors for each `pyleoclim.PSD` object.\n",
    "Similar to `pyleoclim.MultipleSeries`, we may also define a `pyleoclim.MultiplePSD` object for a collection of the `pyleoclim.PSD` objects for operations at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the tableau20 colors\n",
    "tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),    \n",
    "             (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),    \n",
    "             (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),    \n",
    "             (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),    \n",
    "             (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]    \n",
    "  \n",
    "# scale the RGB values to the [0, 1] range, which is the format matplotlib accepts.    \n",
    "for i in range(len(tableau20)):    \n",
    "    r, g, b = tableau20[i]    \n",
    "    tableau20[i] = (r / 255., g / 255., b / 255.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dictionary for the colors\n",
    "clr_dict = {\n",
    "    'EDC': tableau20[0],\n",
    "    'HadCRUT4': tableau20[3],\n",
    "    'GAST': tableau20[4],\n",
    "    'ProbStack': tableau20[5],\n",
    "    'LMR': tableau20[6],\n",
    "}\n",
    "\n",
    "# specify color for each pyleoclim.PSD objects\n",
    "for k, v in clr_dict.items():\n",
    "    psd_wwz[k].plot_kwargs = {'color': v}\n",
    "    \n",
    "# for the period axis customization later\n",
    "period_ticks = [0.5, 1, 2, 5, 10, 20, 100, 1e3, 1e4, 1e5, 1e6]\n",
    "period_ticklabels = ['0.5', '1', '2', '5', '10', '20', '100', '1 k', '10 k', '100 k', '1 m']\n",
    "\n",
    "# define the pyleoclim.MultiplePSD object and visualize the several pyleoclim.PSD objects at once\n",
    "mpsd_obs = pyleo.MultiplePSD([psd_wwz[name] for name in ['EDC', 'HadCRUT4', 'GAST', 'ProbStack', 'LMR']])\n",
    "fig, ax = mpsd_obs.plot(figsize=[8, 4], mute=True)\n",
    "ax.set_xlim([1e7, 0.1])\n",
    "ax.set_ylim([1e-4, 1e8])\n",
    "ax.set_xticks(period_ticks)\n",
    "ax.set_xticklabels(period_ticklabels)\n",
    "ax.set_ylabel('Spectral Density')\n",
    "pyleo.showfig(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have reproduced Fig. 1 of the original paper above.\n",
    "\n",
    "To reproduce the upper panel of Fig. 2, we reset the colors for observations to be grey, and set the opacity via `alpha`, as well as the line width via `linewidth` below.\n",
    "Note that the colors for the PMIP3 simulations will follow a default list of Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_dict = {\n",
    "    'EDC': 'grey',\n",
    "    'HadCRUT4': 'grey',\n",
    "    'GAST': 'grey',\n",
    "    'ProbStack': 'grey',\n",
    "    'LMR': 'grey'\n",
    "}\n",
    "for k, v in clr_dict.items():\n",
    "    psd_wwz[k].plot_kwargs = {'color': v, 'alpha': 0.3, 'linewidth': 1.5}\n",
    "    \n",
    "mpsd_obs = pyleo.MultiplePSD([psd_wwz[name] for name in ['EDC', 'HadCRUT4', 'GAST', 'ProbStack', 'LMR']])\n",
    "\n",
    "period_ticks = [0.5, 1, 2, 5, 10, 20, 100, 1000, 10000, 100000]\n",
    "period_ticklabels = ['0.5', '1', '2', '5', '10', '20', '100', '1 k', '10 k', '100 k']\n",
    "\n",
    "pmip_names = ['bcc_csm1_1', 'CCSM4', 'FGOALS_gl', 'FGOALS_s2', 'IPSL_CM5A_LR', 'MPI_ESM_P', 'CSIRO', 'HadCM3', 'CESM', 'GISS']\n",
    "mpsd_pmip = pyleo.MultiplePSD([psd_wwz[name] for name in pmip_names])\n",
    "fig, ax = mpsd_pmip.plot(figsize=[8, 4], mute=True, cmap='tab10')\n",
    "mpsd_obs.plot(ax=ax, legend=False)\n",
    "ax.set_xlim([1e7, 0.1])\n",
    "ax.set_ylim([1e-4, 1e8])\n",
    "ax.set_xticks(period_ticks)\n",
    "ax.set_xticklabels(period_ticklabels)\n",
    "ax.set_ylabel('Spectral Density')\n",
    "pyleo.showfig(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we reproduce the lower panel of Fig. 2 of the original paper as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_deglacial_dict = {\n",
    "    'trace21ka_full': tableau20[6],\n",
    "    'DGns': tableau20[4],\n",
    "    'SIM2bl': tableau20[0],\n",
    "}\n",
    "for k, v in clr_deglacial_dict.items():\n",
    "    psd_wwz[k].plot_kwargs = {'color': v}\n",
    "\n",
    "\n",
    "period_ticks = [0.5, 1, 2, 5, 10, 20, 100, 1000, 10000, 100000]\n",
    "period_ticklabels = ['0.5', '1', '2', '5', '10', '20', '100', '1 k', '10 k', '100 k']\n",
    "\n",
    "mpsd_deglacial = pyleo.MultiplePSD([psd_wwz[name] for name in ['trace21ka_full', 'DGns', 'SIM2bl']])\n",
    "fig, ax = mpsd_deglacial.plot(figsize=[8, 4], mute=True)\n",
    "mpsd_obs.plot(ax=ax, legend=False)\n",
    "ax.set_xlim([1e7, 0.1])\n",
    "ax.set_ylim([1e-4, 1e8])\n",
    "ax.set_xticks(period_ticks)\n",
    "ax.set_xticklabels(period_ticklabels)\n",
    "ax.set_ylabel('Spectral Density')\n",
    "pyleo.showfig(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation of the scaling exponents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that something is missing comparing our reproduced figures to the figures in the original paper -- the scaling exponents.\n",
    "\n",
    "Below, we use the `pyleoclim.PSD.beta_est()` method to estimate the scaling exponents for each dataset.\n",
    "To do that, we need to specify the frequency range over which we estimate.\n",
    "The estimation is achieved utilizing linear regression in the log-log space.\n",
    "Since the frequency vector we used is `nfft`, which is defined in a linear space, so the frequency points will be denses over the high frequency band and coarser over the low frequency band, and binning is needed prior to the linear regression, so there's an argument called `logf_binning_step` that we need to set.\n",
    "While the default is `max`, which means to use the largest spacing for binning, here we use the first spacing of the frequency vector, as per the original paper.\n",
    "\n",
    "Note that we estimate exponents over two scaling regimes with a break at 400 yrs for the deglacial simualtions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define frequency range for the exponent estimation\n",
    "franges = {\n",
    "    'EDC': [1/50000, 1/1500],\n",
    "    'HadCRUT4': [1/50, 6],\n",
    "    'GAST': [1/100000, 1/2000],\n",
    "    'ProbStack': [1/100000, 1/10000],\n",
    "    'LMR': [1/1000, 1/2],\n",
    "}\n",
    "\n",
    "# for PMIP simulations, we estimation the scaling slope over 2-500 yrs\n",
    "for name in pmip_names:\n",
    "    franges[name] = [1/500, 1/2]\n",
    "\n",
    "beta_est_res = {}\n",
    "for name, frange in franges.items():\n",
    "    beta_est_res[name] = psd_wwz[name].beta_est(fmin=frange[0], fmax=frange[-1], logf_binning_step='first')\n",
    "    \n",
    "# for deglacial model simulations, we have two scaling regimes, one over 20-400 yrs, and another over 400-2000 yrs\n",
    "s_break = 400\n",
    "franges_s = {\n",
    "    'trace21ka_full': [1/s_break, 1/21],  # note that for TraCE-21ka, the slope is estimated over 21-400 yrs due to its temporal resolution \n",
    "    'DGns': [1/s_break, 1/20],\n",
    "    'SIM2bl': [1/s_break, 1/20],\n",
    "}\n",
    "franges_l = {\n",
    "    'trace21ka_full': [1/2000, 1/s_break],\n",
    "    'DGns': [1/2000, 1/s_break],\n",
    "    'SIM2bl': [1/2000, 1/s_break],\n",
    "}\n",
    "\n",
    "beta_est_s_res = {}\n",
    "for name, frange in franges_s.items():\n",
    "    beta_est_s_res[name] = psd_wwz[name].beta_est(fmin=frange[0], fmax=frange[-1], logf_binning_step='first')\n",
    "    \n",
    "beta_est_l_res = {}\n",
    "for name, frange in franges_l.items():\n",
    "    beta_est_l_res[name] = psd_wwz[name].beta_est(fmin=frange[0], fmax=frange[-1], logf_binning_step='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we re-plot the figures with the estimated scaling exponents displayed in the legend and visualized via straight lines in the figure.\n",
    "Below is for Fig. 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_dict = {\n",
    "    'EDC': tableau20[0],\n",
    "    'HadCRUT4': tableau20[3],\n",
    "    'GAST': tableau20[4],\n",
    "    'ProbStack': tableau20[5],\n",
    "    'LMR': tableau20[6],\n",
    "}\n",
    "\n",
    "for k, v in clr_dict.items():\n",
    "    psd_wwz[k].plot_kwargs = {'color': v}\n",
    "    \n",
    "period_ticks = [0.5, 1, 2, 5, 10, 20, 100, 1e3, 1e4, 1e5, 1e6]\n",
    "period_ticklabels = ['0.5', '1', '2', '5', '10', '20', '100', '1 k', '10 k', '100 k', '1 m']\n",
    "\n",
    "mpsd_obs = pyleo.MultiplePSD([psd_wwz[name] for name in ['EDC', 'HadCRUT4', 'GAST', 'ProbStack', 'LMR']])\n",
    "fig, ax = mpsd_obs.plot(figsize=[8, 4], mute=True)\n",
    "ax.set_xlim([1e7, 0.1])\n",
    "ax.set_ylim([1e-4, 1e8])\n",
    "ax.set_xticks(period_ticks)\n",
    "ax.set_xticklabels(period_ticklabels)\n",
    "\n",
    "labels = ax.get_legend_handles_labels()[-1]\n",
    "new_labels = []\n",
    "i = 0\n",
    "for name in ['EDC', 'HadCRUT4', 'GAST', 'ProbStack', 'LMR']:\n",
    "    res = beta_est_res[name]\n",
    "    ax.plot(1/res['f_binned'], res['Y_reg'], linestyle='--', color='k', linewidth=1, zorder=99)\n",
    "    new_labels.append(fr'{labels[i]} ($\\beta=${res[\"beta\"]:.2f}$\\pm${res[\"std_err\"]:.2f})')\n",
    "    i += 1\n",
    "\n",
    "ax.legend(labels=new_labels)\n",
    "ax.set_ylabel('Spectral Density')\n",
    "pyleo.showfig(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the upper panel of Fig. 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_dict = {\n",
    "    'EDC': 'grey',\n",
    "    'HadCRUT4': 'grey',\n",
    "    'GAST': 'grey',\n",
    "    'ProbStack': 'grey',\n",
    "    'LMR': 'grey'\n",
    "}\n",
    "for k, v in clr_dict.items():\n",
    "    psd_wwz[k].plot_kwargs = {'color': v, 'alpha': 0.2, 'linewidth': 1.5}\n",
    "    \n",
    "mpsd_obs = pyleo.MultiplePSD([psd_wwz[name] for name in ['EDC', 'HadCRUT4', 'GAST', 'ProbStack', 'LMR']])\n",
    "\n",
    "\n",
    "period_ticks = [0.5, 1, 2, 5, 10, 20, 100, 1e3, 1e4, 1e5]\n",
    "period_ticklabels = ['0.5', '1', '2', '5', '10', '20', '100', '1 k', '10 k', '100 k']\n",
    "\n",
    "fig, ax = mpsd_pmip.plot(figsize=[8, 4], mute=True, cmap='tab10')\n",
    "\n",
    "mpsd_obs.plot(ax=ax, legend=False)\n",
    "ax.set_xlim([1e6, 0.1])\n",
    "ax.set_ylim([1e-4, 1e8])\n",
    "ax.set_xticks(period_ticks)\n",
    "ax.set_xticklabels(period_ticklabels)\n",
    "\n",
    "labels = ax.get_legend_handles_labels()[-1]\n",
    "new_labels = []\n",
    "i = 0\n",
    "for name in pmip_names:\n",
    "    res = beta_est_res[name]\n",
    "    ax.plot(1/res['f_binned'], res['Y_reg'], linestyle='--', color='k', linewidth=1, zorder=99)\n",
    "    new_labels.append(fr'{labels[i]} ($\\beta=${res[\"beta\"]:.2f}$\\pm${res[\"std_err\"]:.2f})')\n",
    "    i += 1\n",
    "\n",
    "ax.legend(labels=new_labels, bbox_to_anchor=(1.5, 1))\n",
    "ax.set_ylabel('Spectral Density')\n",
    "pyleo.showfig(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and the lower panel of Fig. 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_dict = {\n",
    "    'EDC': 'grey',\n",
    "    'HadCRUT4': 'grey',\n",
    "    'GAST': 'grey',\n",
    "    'ProbStack': 'grey',\n",
    "    'LMR': 'grey'\n",
    "}\n",
    "for k, v in clr_dict.items():\n",
    "    psd_wwz[k].plot_kwargs = {'color': v, 'alpha': 0.2, 'linewidth': 1.5}\n",
    "    \n",
    "mpsd_obs = pyleo.MultiplePSD([psd_wwz[name] for name in ['EDC', 'HadCRUT4', 'GAST', 'ProbStack', 'LMR']])\n",
    "\n",
    "clr_deglacial_dict = {\n",
    "    'trace21ka_full': tableau20[6],\n",
    "    'DGns': tableau20[4],\n",
    "    'SIM2bl': tableau20[0],\n",
    "}\n",
    "for k, v in clr_deglacial_dict.items():\n",
    "    psd_wwz[k].plot_kwargs = {'color': v}\n",
    "\n",
    "period_ticks = [0.5, 1, 2, 5, 10, 20, 100, 1e3, 1e4, 1e5]\n",
    "period_ticklabels = ['0.5', '1', '2', '5', '10', '20', '100', '1 k', '10 k', '100 k']\n",
    "\n",
    "fig, ax = mpsd_deglacial.plot(figsize=[8, 4], mute=True)\n",
    "mpsd_obs.plot(ax=ax, legend=False)\n",
    "ax.set_xlim([1e6, 0.1])\n",
    "ax.set_ylim([1e-4, 1e8])\n",
    "ax.set_xticks(period_ticks)\n",
    "ax.set_xticklabels(period_ticklabels)\n",
    "\n",
    "labels = ax.get_legend_handles_labels()[-1]\n",
    "new_labels = []\n",
    "i = 0\n",
    "for name in ['trace21ka_full', 'DGns', 'SIM2bl']:\n",
    "    res_s = beta_est_s_res[name]\n",
    "    res_l = beta_est_l_res[name]\n",
    "    ax.plot(1/res_s['f_binned'], res_s['Y_reg'], linestyle='--', color='k', linewidth=1, zorder=99)\n",
    "    ax.plot(1/res_l['f_binned'], res_l['Y_reg'], linestyle='--', color='k', linewidth=1, zorder=99)\n",
    "    beta_s_str = r'$\\beta_{DC}$'\n",
    "    beta_s = res_s['beta']\n",
    "    err_s = res_s['std_err']\n",
    "    beta_l_str = r'$\\beta_{CM}$'\n",
    "    beta_l = res_l['beta']\n",
    "    err_l = res_l['std_err']\n",
    "    new_labels.append(fr'{labels[i]} ({beta_l_str}$=${beta_l:.2f}$\\pm${err_l:.2f}; {beta_s_str}$=${beta_s:.2f}$\\pm${err_s:.2f})')\n",
    "    i += 1\n",
    "\n",
    "ax.legend(labels=new_labels, loc='upper right', bbox_to_anchor=(1.1, 1))\n",
    "ax.set_ylabel('Spectral Density')\n",
    "pyleo.showfig(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II (A) spectral analysis of `EnsembleSeries` with the Lomb-Scargle method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practice, we will load the LMR reconstructed GMST ensemble, and perform spectral analysis on it with the Lomb-Scargle method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the LMR GMST ensemble\n",
    "!wget https://atmos.washington.edu/%7Ehakim/lmr/LMRv2/gmt_MCruns_ensemble_full_LMRv2.1.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "with xr.open_dataset('gmt_MCruns_ensemble_full_LMRv2.1.nc') as ds:\n",
    "    print(ds)\n",
    "    lmr_gmt = ds['gmt'].values\n",
    "    lmr_time = ds['time'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the time axis with an numpy array of years\n",
    "print(lmr_time)\n",
    "lmr_time = np.arange(2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt, nMC, nEns = np.shape(lmr_gmt)\n",
    "ts_lmr_members = []\n",
    "for i in range(nMC):\n",
    "    for j in range(nEns):\n",
    "        ts_lmr_members.append(pyleo.Series(time=lmr_time, value=lmr_gmt[:, i, j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all the series have been put into an `Ensemble` object, they can easily be manipulated. First, let's plot the time evolving distribution of the ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_lmr = pyleo.EnsembleSeries(ts_lmr_members)        \n",
    "fig, ax = ms_lmr.plot_envelope()\n",
    "pyleo.closefig(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the variance of the median decreases back in time, but that is associated with a wide increase in the uncertainties. This is simply due to attrition: the further back you go, the fewer annually-resolved proxies are constraining the reconstriction, so it reverts to a flat-ish line, with broad uncertainties to tell you not to take this literally.\n",
    "\n",
    "But there's more! In one flourish of the wand, you can also apply a method (say, Lomb-Scargle spectral analysis) to all ensemble members at once. It does require a little patience to see this to completion, but that is the only way to truly quantify uncertainties in the spectrum of this index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here for spectral analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this function is a `MultiplePSD` object, and it too knows how to plot distributions in one line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to visualize the result using the MultiplePSD.plot_envelope() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II (B) a practice of comparing results from different spectral analysis method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for the reader to seize control of this tool and see what they might do with it. Some suggestions:\n",
    "\n",
    "We have performed spectral analysis using the WWZ method above, yet `Pyleoclim` provides also the classic multi-taper method (MTM, [Thomson 1982](https://ieeexplore.ieee.org/abstract/document/1456701/)) and Lomb-Scargle periodogram ([Lomb 1976](https://link.springer.com/article/10.1007%2FBF00648343), [Scargle 1982](https://link.springer.com/article/10.1007%2FBF00648343)).\n",
    "The MTM method can handle only evenly-spaced data, so for paleo-records, we need to first perform an interpolation prior to the spectral analysis.\n",
    "The Lomb-Scargle peridogram, on the other hand, can handle unevenly-spaced data without interpolation.\n",
    "\n",
    "For our practice, we'd like to perform spectral analysis on an unevenly-spaced time series using all the three methods and compare the results:\n",
    "1. [WWZ](https://pyleoclim-util.readthedocs.io/en/stable/utils/spectral/wwz_psd.html?highlight=wwz_psd), or `pyleoclim.Series.spectral(method='wwz')` with appropriate arguments\n",
    "2. [interpolation](https://pyleoclim-util.readthedocs.io/en/stable/core/Series/interp.html#pyleoclim.core.ui.Series.interp) + [MTM](https://pyleoclim-util.readthedocs.io/en/stable/utils/spectral/mtm.html?highlight=mtm), or `pyleoclim.Series.interp()` + `pyleoclim.Series.spectral(method='mtm')` with appropriate arguments\n",
    "3. [Lomb-Scargle](https://pyleoclim-util.readthedocs.io/en/stable/utils/spectral/lombscargle.html?highlight=lomb%20scargle#pyleoclim.utils.spectral.lomb_scargle), or `pyleoclim.Series.spectral(method='lomb_scargle')` with appropriate arguments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details of the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please complete the following steps:\n",
    "\n",
    "1. Perform spectral analysis on the EDC dataset using WWZ, MTM, and Lomb-Scargle, and get three `pyleoclim.PSD` objects.\n",
    "2. Estimate the scaling exponent over the frequency band [1/50000, 1/1500].\n",
    "3. Visualize the three `pyleoclim.PSD` objects along with the information of the scaling exponents (with text in the legend and straight lines in the figure).\n",
    "4. Compare the results from three methods, and discuss what you find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# hint: to perform interpolation, you may need to enable extrapolation following the doc:\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.interp1d.html\n",
    "# or pyleoclim.Series.interp(..., fill_value='extrapolate')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
