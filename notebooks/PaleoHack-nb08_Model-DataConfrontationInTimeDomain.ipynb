{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aboriginal-layer",
   "metadata": {},
   "source": [
    "<img src='https://github.com/LinkedEarth/Logos/raw/master/PYLEOCLIM_logo_HORZ-01.png' width=\"800\">\n",
    "\n",
    "# 8. Model-Data Confrontation in the time domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-slope",
   "metadata": {},
   "source": [
    "In the notebook, we demonstrate how to use `Pyleoclim` to load LiPD files, and compare proxy records with the [last millennium reanalysis (LMR)](https://cpo.noaa.gov/News/News-Article/ArtMID/6226/ArticleID/1807/Last-Millennium-Reanalysis-now-at-NOAAs-National-Centers-for-Environmental-Information-marking-major-milestone) at  proxy locales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-jumping",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install demjson --upgrade  # addresses this setuptools/demjson incompatibility: https://github.com/dmeranda/demjson/issues/40\n",
    "# load essential packages    \n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import xarray as xr\n",
    "import pyleoclim as pyleo  # make an alias name for \"pyleoclim\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-twelve",
   "metadata": {},
   "source": [
    "## Load proxy data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-fortune",
   "metadata": {},
   "source": [
    "The proxy record we'd like to load is [this one](http://wiki.linked.earth/LPD81e53153.temperature), attached to [Tierney et al (2015)](http://dx.doi.org/10.1126/sciadv.1500682). It is an SST reconstruction based on the TEX86 proxy from two cores from the horn of Africa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pyleo.Lipd(usr_path='../data/Afr-P178-15P.Tierney.2015.lpd')\n",
    "Ocn_136 = d.to_LipdSeries(0) \n",
    "Ocn_137 = d.to_LipdSeries(2)   \n",
    "Ocn_136.label = 'Ocn_136'\n",
    "Ocn_137.label = 'Ocn_137'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-hampton",
   "metadata": {},
   "source": [
    "Let's plot the two cores on the same graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-syndication",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = Ocn_137.plot(mute=True)\n",
    "Ocn_136.plot(ax=ax)\n",
    "pyleo.showfig(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-harbor",
   "metadata": {},
   "source": [
    "We'd like to see how this compares to the [last millennium reanalysis](https://cpo.noaa.gov/News/News-Article/ArtMID/6226/ArticleID/1807/Last-Millennium-Reanalysis-now-at-NOAAs-National-Centers-for-Environmental-Information-marking-major-milestone) (LMR, [Hakim et al. 2016](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2016JD024751), [Tardif et al. 2019](https://cp.copernicus.org/articles/15/1251/2019/)) at the same location. Note that LMR knows nothing of this dataset, as it (currently) only uses annually-resolved records. Thus, this exercise can serve as independent validation of LMR.  Let us first extract the geographical coordinates of the core:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "tslist = d.to_tso()\n",
    "plat = tslist[0]['geo_meanLat']\n",
    "plon = tslist[0]['geo_meanLon']\n",
    "pid = 'Ocn_136'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-ridge",
   "metadata": {},
   "source": [
    "Now, let's move on to extract the LMR-reconstructed temperature series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-financing",
   "metadata": {},
   "source": [
    "## Extract LMR-reconstructed temperature series\n",
    "\n",
    "We will use the sea-surface temperature full grid ensemble [mean](https://atmos.washington.edu/%7Ehakim/lmr/LMRv2/sst_MCruns_ensemble_mean_LMRv2.1.nc) and [spread](https://atmos.washington.edu/%7Ehakim/lmr/LMRv2/sst_MCruns_ensemble_spread_LMRv2.1.nc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_url = 'https://atmos.washington.edu/%7Ehakim/lmr/LMRv2/sst_MCruns_ensemble_mean_LMRv2.1.nc'\n",
    "spread_url = 'https://atmos.washington.edu/%7Ehakim/lmr/LMRv2/sst_MCruns_ensemble_spread_LMRv2.1.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the files\n",
    "! wget $mean_url\n",
    "! wget $spread_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5f2c24",
   "metadata": {},
   "source": [
    "To manipulate netCDF files, we will be using a package called [xarray](http://xarray.pydata.org/en/stable/#). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f528693",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_mean = xr.open_dataset('sst_MCruns_ensemble_mean_LMRv2.1.nc')\n",
    "ds_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e835ddbb",
   "metadata": {},
   "source": [
    "The file contains sea surface temperature information with dimensions: time, Monte-Carlo run, latitude, and longitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090972fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_spread = xr.open_dataset('sst_MCruns_ensemble_spread_LMRv2.1.nc')\n",
    "ds_spread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-pollution",
   "metadata": {},
   "source": [
    "Let's select the nearest gridpoint in the LMR dataset to our proxy record. `xarray` has a built-in function to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c093c25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_mean = ds_mean['sst'].sel(lat=plat,lon=plon,method='nearest')\n",
    "sst_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3ca05a",
   "metadata": {},
   "source": [
    "Note that the array is now in dimensions of time and Monte Carlo runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ce912",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_spread = ds_spread['sst'].sel(lat=plat,lon=plon,method='nearest')\n",
    "sst_spread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-improvement",
   "metadata": {},
   "source": [
    "Now the grid point is located, we are able to define `pyleoclim.EnsembleSeries` for the LMR data.\n",
    "Note that a `pyleoclim.EnsembleSeries` is simply a list of `pyleoclim.Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-missouri",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dimension sizes\n",
    "nt, nEns = np.shape(sst_mean)\n",
    "\n",
    "# the dictionary to store pyleoclim.EnsembleSeries\n",
    "ms_mean = {}\n",
    "ms_spread = {}\n",
    "\n",
    "ts_mean_list = []\n",
    "ts_spread_list = []\n",
    "for i in range(nEns):\n",
    "    ts_mean_tmp = pyleo.Series(\n",
    "            time=np.arange(0, 2001),\n",
    "            value=sst_mean[:, i],\n",
    "            time_name='Time',\n",
    "            value_name='LMR-temp.',\n",
    "            time_unit='year CE',\n",
    "            value_unit='K',\n",
    "        )\n",
    "    ts_spread_tmp = pyleo.Series(\n",
    "            time=np.arange(0, 2001),\n",
    "            value=sst_spread[:, i],\n",
    "            time_name='Time',\n",
    "            value_name='LMR-temp.',\n",
    "            time_unit='year CE',\n",
    "            value_unit='K',\n",
    "        )\n",
    "    ts_mean_list.append(ts_mean_tmp)\n",
    "    ts_spread_list.append(ts_spread_tmp)\n",
    "    \n",
    "# define pyleoclim.EnsembleSeries\n",
    "ms_mean[pid] = pyleo.EnsembleSeries(series_list=ts_mean_list)\n",
    "ms_spread[pid] = pyleo.EnsembleSeries(series_list=ts_spread_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-drilling",
   "metadata": {},
   "source": [
    "Now we let's do a quick visualization of the data with two available plotting methods:\n",
    "1. `.plot_traces()`: display several example members\n",
    "2. `.plot_envelope()`: display all members as an envelope plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = ms_mean['Ocn_136'].plot_traces() # display several example members\n",
    "fig, ax = ms_mean['Ocn_136'].plot_envelope() # display all members as an envelope plot\n",
    "\n",
    "fig, ax = ms_spread['Ocn_136'].plot_traces() # display several example members\n",
    "fig, ax = ms_spread['Ocn_136'].plot_envelope() # display all members as an envelope plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-latest",
   "metadata": {},
   "source": [
    "Note, however, the ensemble of the means is different from the ensemble of the original reconstructed temperature series.\n",
    "To get a flavor of the original ensemble, we plot the ensemble GMST below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download LMR GMST ensembles\n",
    "!wget https://atmos.washington.edu/%7Ehakim/lmr/LMRv2/gmt_MCruns_ensemble_full_LMRv2.1.nc\n",
    "!mv gmt_MCruns_ensemble_full_LMRv2.1.nc ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca2887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_gmst = xr.open_dataset('../data/gmt_MCruns_ensemble_full_LMRv2.1.nc')\n",
    "ds_gmst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exact data and define EnsembleSeries object\n",
    "ts_gmt_list = []\n",
    "nt, nMC, nM = np.shape(ds_gmst['gmt'])\n",
    "for i in range(nMC):\n",
    "    for j in range(nM):\n",
    "        ts_gmt_tmp = pyleo.Series(\n",
    "                time=np.arange(2001),\n",
    "                value=ds_gmst['gmt'][:,i,j],\n",
    "                time_name='Time',\n",
    "                value_name='LMR-GMST',\n",
    "                time_unit='AD',\n",
    "                value_unit='K',\n",
    "            )\n",
    "    ts_gmt_list.append(ts_gmt_tmp)\n",
    "\n",
    "ms_gmt = pyleo.EnsembleSeries(ts_gmt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-sender",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "fig, ax = ms_gmt.plot_traces()\n",
    "fig, ax = ms_gmt.plot_envelope()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-simple",
   "metadata": {},
   "source": [
    "## Comparing the two reconstructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-fancy",
   "metadata": {},
   "source": [
    "Now, back to the ensemble means and spreads, we are ready to perform model-data comparison.\n",
    "Since the LMR reconstruction is expressed as anomalies, we need to first calculate the anomaly series from the proxy record before the comparison. To do so, we simply call the `pyleoclim.Series.anomaly()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = ms_mean['Ocn_136'].plot_envelope(mute=True,curve_lw=0.5,curve_clr='black',shade_clr='gray')\n",
    "Ocn_137.anomaly().plot(ax=ax, zorder=100)  # adjust zorder to reveal the curve\n",
    "Ocn_136.anomaly().plot(ax=ax, zorder=100)\n",
    "pyleo.showfig(fig)\n",
    "pyleo.closefig(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-collapse",
   "metadata": {},
   "source": [
    "We can see that the timing of industrial warming is consistent between the two cores and LMR, though pre-indsutrial variability is severely damped in LMR (because od the lack of nearby, anually resolved proxy records) particularly in the first millennium. This is because of the attrition of whatever few annually-resolved proxies there are in that part of the world, most likely coral records from the Indian Ocean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-cancellation",
   "metadata": {},
   "source": [
    "Now we calculate the correlation between the LMR median curve and the proxy record, after which we visualize the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-prevention",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_ens = ms_mean['Ocn_136'].correlation(Ocn_136)\n",
    "print(corr_ens)\n",
    "\n",
    "fig, ax = corr_ens.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-runner",
   "metadata": {},
   "source": [
    "Not surprisingly, one finds a positive correlation, consistent among ensemble members, likely driven by the anthropogenic warming trend. More instructive would be to look at the correlation over the Common Era as a whole.\n",
    "\n",
    "**Exercise 8.1** \n",
    "How does this picture change when using the longer core (Ocn_137)?\n",
    "\n",
    "**Exercise 8.2**\n",
    "How does this picture change when using either core and the global mean surface temperature series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-dynamics",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
